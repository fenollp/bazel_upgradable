load(":utils.bzl", "sat")
load(
    "@bazel_tools//tools/build_defs/repo:utils.bzl",
    "patch",
    "read_netrc",
    "update_attrs",
    "use_netrc",
    "workspace_and_buildfile",
)

_AUTH_PATTERN_DOC = """An optional dict mapping host names to custom authorization patterns.

If a URL's host name is present in this dict the value will be used as a pattern when
generating the authorization header for the http request. This enables the use of custom
authorization schemes used in a lot of common cloud storage providers.

The pattern currently supports 2 tokens: <code>&lt;login&gt;</code> and
<code>&lt;password&gt;</code>, which are replaced with their equivalent value
in the netrc file for the same host name. After formatting, the result is set
as the value for the <code>Authorization</code> field of the HTTP request.

Example attribute and netrc for a http download to an oauth2 enabled API using a bearer token:

<pre>
auth_patterns = {
    "storage.cloudprovider.com": "Bearer &lt;password&gt;"
}
</pre>

netrc:

<pre>
machine storage.cloudprovider.com
        password RANDOM-TOKEN
</pre>

The final HTTP request would have the following header:

<pre>
Authorization: Bearer RANDOM-TOKEN
</pre>
"""

def _get_auth(ctx, urls):
    """Given the list of URLs obtain the correct auth dict."""
    if ctx.attr.netrc:
        netrc = read_netrc(ctx, ctx.attr.netrc)
        return use_netrc(netrc, urls, ctx.attr.auth_patterns)

    if "HOME" in ctx.os.environ and not ctx.os.name.startswith("windows"):
        netrcfile = "%s/.netrc" % (ctx.os.environ["HOME"])
        if ctx.execute(["test", "-f", netrcfile]).return_code == 0:
            netrc = read_netrc(ctx, netrcfile)
            return use_netrc(netrc, urls, ctx.attr.auth_patterns)

    if "USERPROFILE" in ctx.os.environ and ctx.os.name.startswith("windows"):
        netrcfile = "%s/.netrc" % (ctx.os.environ["USERPROFILE"])
        if ctx.path(netrcfile).exists:
            netrc = read_netrc(ctx, netrcfile)
            return use_netrc(netrc, urls, ctx.attr.auth_patterns)

    return {}

_ATTRS_INHERITED_FROM_HTTP_ARCHIVE = {
    "netrc": attr.string(
        doc = "Location of the .netrc file to use for authentication",
    ),
    "auth_patterns": attr.string_dict(
        doc = _AUTH_PATTERN_DOC,
    ),
    "canonical_id": attr.string(
        doc = """A canonical id of the archive downloaded.

If specified and non-empty, bazel will not take the archive from cache,
unless it was added to the cache by a request with the same canonical id.
""",
    ),
    "patches": attr.label_list(
        default = [],
        doc =
            "A list of files that are to be applied as patches after " +
            "extracting the archive. By default, it uses the Bazel-native patch implementation " +
            "which doesn't support fuzz match and binary patch, but Bazel will fall back to use " +
            "patch command line tool if `patch_tool` attribute is specified or there are " +
            "arguments other than `-p` in `patch_args` attribute.",
    ),
    "patch_tool": attr.string(
        default = "",
        doc = "The patch(1) utility to use. If this is specified, Bazel will use the specifed " +
              "patch tool instead of the Bazel-native patch implementation.",
    ),
    "patch_args": attr.string_list(
        default = ["-p0"],
        doc =
            "The arguments given to the patch tool. Defaults to -p0, " +
            "however -p1 will usually be needed for patches generated by " +
            "git. If multiple -p arguments are specified, the last one will take effect." +
            "If arguments other than -p are specified, Bazel will fall back to use patch " +
            "command line tool instead of the Bazel-native patch implementation. When falling " +
            "back to patch command line tool and patch_tool attribute is not specified, " +
            "`patch` will be used.",
    ),
    "patch_cmds": attr.string_list(
        default = [],
        doc = "Sequence of Bash commands to be applied on Linux/Macos after patches are applied.",
    ),
    "patch_cmds_win": attr.string_list(
        default = [],
        doc = "Sequence of Powershell commands to be applied on Windows after patches are " +
              "applied. If this attribute is not set, patch_cmds will be executed on Windows, " +
              "which requires Bash binary to exist.",
    ),
    "build_file": attr.label(
        allow_single_file = True,
        doc =
            "The file to use as the BUILD file for this repository." +
            "This attribute is an absolute label (use '@//' for the main " +
            "repo). The file does not need to be named BUILD, but can " +
            "be (something like BUILD.new-repo-name may work well for " +
            "distinguishing it from the repository's actual BUILD files. " +
            "Either build_file or build_file_content can be specified, but " +
            "not both.",
    ),
    "build_file_content": attr.string(
        doc =
            "The content for the BUILD file for this repository. " +
            "Either build_file or build_file_content can be specified, but " +
            "not both.",
    ),
    "workspace_file": attr.label(
        doc =
            "The file to use as the `WORKSPACE` file for this repository. " +
            "Either `workspace_file` or `workspace_file_content` can be " +
            "specified, or neither, but not both.",
    ),
    "workspace_file_content": attr.string(
        doc =
            "The content for the WORKSPACE file for this repository. " +
            "Either `workspace_file` or `workspace_file_content` can be " +
            "specified, or neither, but not both.",
    ),
}

_attrs_for_upgradable_repository = _ATTRS_INHERITED_FROM_HTTP_ARCHIVE
_attrs_for_upgradable_repository["branch"] = attr.string()
_attrs_for_upgradable_repository["remote"] = attr.string(mandatory = True)
_attrs_for_upgradable_repository["tag"] = attr.string()
_attrs_for_upgradable_repository["sha256"] = attr.string(doc = "Internal")
_attrs_for_upgradable_repository["strip_prefix"] = attr.string(doc = "Internal")
_attrs_for_upgradable_repository["urls"] = attr.string_list(doc = "Internal")

def _prefix_for(hosting, repo, commit):
    if hosting == "github":
        return "{}-{}".format(repo, commit)
    fail("PLEASE REPORT: _prefix_for({}, {}, {})".format(hosting, repo, commit))

def _archive_for(hosting, host, owner, repo, commit):
    if hosting == "github":
        return "https://{}/{}/{}/archive/{}.tar.gz".format(host, owner, repo, commit)
    fail("PLEASE REPORT: _archive_for({}, {}, {}, {}, {})".format(hosting, host, owner, repo, commit))

def _impl_for_upgradable_repository(ctx):
    """Implementation of the upgradable_repository rule."""
    if ctx.attr.build_file and ctx.attr.build_file_content:
        fail("Only one of build_file and build_file_content can be provided.")

    if not ctx.attr.branch and not ctx.attr.tag:
        ctx.attr["branch"] = "master"
    if len([None for x in [ctx.attr.branch, ctx.attr.tag] if x]) != 1:
        fail("Exactly one of branch or tag must be provided")

    remote_split = ctx.attr.remote.split("/")
    if len(remote_split) != 5:
        fail("A remote must be of the form scheme://host/owner/repo")
    scheme, _, host, owner, repo = remote_split
    if scheme == "git:":
        if repo.endswith(".git"):
            repo = repo[:-len(".git")]
    else:
        fail("Unsupported scheme '{}'".format(scheme))
    hosting = None
    if host == "github.com":
        hosting = "github"
    else:
        fail("Unsupported hosting with {}".format(host))

    # TODO: use "GITHUB_TOKEN" in ctx.os.environ || netrc or other auth means

    all_urls = None
    strip_prefix = None
    if ctx.attr.sha256 and ctx.attr.strip_prefix and ctx.attr.urls:
        all_urls = ctx.attr.urls
        strip_prefix = ctx.attr.strip_prefix
    else:
        ref, commit = sat(ctx, ctx.attr.remote, ctx.attr.branch, ctx.attr.tag)

        args = ["Branch", ref, ctx.attr.remote, ctx.attr.branch, commit]
        if ctx.attr.tag:
            args = ["Tag", ref, ctx.attr.remote, ctx.attr.tag, commit]
        print("{} {} of {} satisfies constraint {} (commit = {})".format(*args))

        all_urls = [_archive_for(hosting, host, owner, repo, commit)]
        strip_prefix = _prefix_for(hosting, repo, commit)

    auth = _get_auth(ctx, all_urls)
    download_info = ctx.download_and_extract(
        all_urls,
        "",
        ctx.attr.sha256,
        "tar.gz",
        strip_prefix,
        canonical_id = ctx.attr.canonical_id,
        auth = auth,
    )
    workspace_and_buildfile(ctx)
    patch(ctx)
    attrs = _attrs_for_upgradable_repository.keys()
    return update_attrs(ctx.attr, attrs, {
        "sha256": download_info.sha256,
        "strip_prefix": strip_prefix,
        "urls": all_urls,
    })

upgradable_repository = repository_rule(
    implementation = _impl_for_upgradable_repository,
    attrs = _attrs_for_upgradable_repository,
)
